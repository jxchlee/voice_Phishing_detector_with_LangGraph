import whisper
import librosa
import torch
import os
from datetime import datetime
import argparse

class VoiceToTextConverter:
    def __init__(self, model_size="base"):
        """
        Whisper ëª¨ë¸ ì´ˆê¸°í™”
        model_size: tiny, base, small, medium, large
        """
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤: {self.device}")
        
        if torch.cuda.is_available():
            print(f"GPU: {torch.cuda.get_device_name(0)}")
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB")
            
            # large ëª¨ë¸ ì‚¬ìš© ì‹œ ë©”ëª¨ë¦¬ ê²½ê³ 
            if model_size == "large" and gpu_memory < 8:
                print("âš ï¸  ê²½ê³ : large ëª¨ë¸ì€ 8GB ì´ìƒì˜ GPU ë©”ëª¨ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
                print("   ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ CPU ì‚¬ìš©ì„ ê³ ë ¤í•˜ì„¸ìš”.")
        else:
            print("GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        print(f"Whisper {model_size} ëª¨ë¸ì„ ë¡œë”© ì¤‘...")
        
        try:
            self.model = whisper.load_model(model_size, device=self.device)
            print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        except Exception as e:
            if "out of memory" in str(e).lower():
                print("GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ CPUë¡œ ì „í™˜í•©ë‹ˆë‹¤...")
                self.device = "cpu"
                self.model = whisper.load_model(model_size, device=self.device)
                print("CPUë¡œ ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
            else:
                raise e
    
    def transcribe_audio(self, audio_file_path, language="ko"):
        """
        librosaë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        """
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(audio_file_path):
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file_path}")
        
        print(f"ìŒì„± íŒŒì¼ ë³€í™˜ ì¤‘: {audio_file_path}")
        print(f"íŒŒì¼ í¬ê¸°: {os.path.getsize(audio_file_path)} bytes")
        
        try:
            # librosaë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ (16kHzë¡œ ë¦¬ìƒ˜í”Œë§)
            print("ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë”© ì¤‘...")
            audio_data, sr = librosa.load(audio_file_path, sr=16000)
            print(f"ì˜¤ë””ì˜¤ ë¡œë“œ ì™„ë£Œ: ìƒ˜í”Œë ˆì´íŠ¸={sr}Hz, ê¸¸ì´={len(audio_data)/sr:.2f}ì´ˆ")
            
            # Whisperë¡œ ìŒì„± ì¸ì‹ (numpy ë°°ì—´ ì§ì ‘ ì „ë‹¬)
            print("ìŒì„± ì¸ì‹ ì²˜ë¦¬ ì¤‘...")
            
            # NaN ê°’ ë°©ì§€ë¥¼ ìœ„í•œ ì¶”ê°€ ì˜µì…˜ë“¤
            transcribe_options = {
                "language": language,
                "verbose": True,
                "fp16": False,  # NaN ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ fp16 ë¹„í™œì„±í™”
                "temperature": 0.0,  # ì˜¨ë„ë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì•ˆì •ì„± í–¥ìƒ
                "compression_ratio_threshold": 2.4,
                "logprob_threshold": -1.0,
                "no_speech_threshold": 0.6
            }
            
            # ê¸´ ì˜¤ë””ì˜¤ì˜ ê²½ìš° ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í•  ì²˜ë¦¬
            if len(audio_data) > 16000 * 30:  # 30ì´ˆ ì´ìƒì¸ ê²½ìš°
                print("ê¸´ ì˜¤ë””ì˜¤ íŒŒì¼ì…ë‹ˆë‹¤. ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤...")
                result = self._process_long_audio(audio_data, transcribe_options)
            else:
                result = self.model.transcribe(audio_data, **transcribe_options)
            
            print("âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ!")
            return result
            
        except Exception as e:
            raise Exception(f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {str(e)}")
    
    def _process_long_audio(self, audio_data, transcribe_options):
        """
        ê¸´ ì˜¤ë””ì˜¤ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬
        """
        import numpy as np
        
        chunk_length = 30  # 30ì´ˆ ì²­í¬
        sample_rate = 16000
        chunk_samples = chunk_length * sample_rate
        
        # ì „ì²´ ê²°ê³¼ë¥¼ ì €ì¥í•  êµ¬ì¡°
        full_result = {
            "text": "",
            "segments": [],
            "language": transcribe_options.get("language", "ko")
        }
        
        # ì˜¤ë””ì˜¤ë¥¼ ì²­í¬ë¡œ ë¶„í• 
        total_chunks = len(audio_data) // chunk_samples + (1 if len(audio_data) % chunk_samples > 0 else 0)
        print(f"ì´ {total_chunks}ê°œ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤...")
        
        current_time_offset = 0.0
        
        for i in range(total_chunks):
            start_sample = i * chunk_samples
            end_sample = min((i + 1) * chunk_samples, len(audio_data))
            chunk_audio = audio_data[start_sample:end_sample]
            
            # ë„ˆë¬´ ì§§ì€ ì²­í¬ëŠ” ê±´ë„ˆë›°ê¸°
            if len(chunk_audio) < sample_rate * 0.5:  # 0.5ì´ˆ ë¯¸ë§Œ
                continue
            
            print(f"ì²­í¬ {i+1}/{total_chunks} ì²˜ë¦¬ ì¤‘... ({start_sample/sample_rate:.1f}s - {end_sample/sample_rate:.1f}s)")
            
            try:
                # ê° ì²­í¬ ì²˜ë¦¬
                chunk_result = self.model.transcribe(chunk_audio, **transcribe_options)
                
                # í…ìŠ¤íŠ¸ ê²°í•©
                if chunk_result["text"].strip():
                    full_result["text"] += chunk_result["text"] + " "
                
                # ì„¸ê·¸ë¨¼íŠ¸ ì‹œê°„ ì¡°ì • í›„ ì¶”ê°€
                for segment in chunk_result["segments"]:
                    adjusted_segment = segment.copy()
                    adjusted_segment["start"] += current_time_offset
                    adjusted_segment["end"] += current_time_offset
                    full_result["segments"].append(adjusted_segment)
                
            except Exception as e:
                print(f"ì²­í¬ {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                continue
            
            current_time_offset = end_sample / sample_rate
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        full_result["text"] = full_result["text"].strip()
        
        print(f"ëª¨ë“  ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ! ì´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(full_result['text'])}ì")
        return full_result
    
    def save_transcript(self, result, output_file=None, base_filename=None):
        """
        ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        """
        # src/text ë””ë ‰í† ë¦¬ ìƒì„±
        text_dir = "src/text"
        os.makedirs(text_dir, exist_ok=True)
        
        if output_file is None:
            if base_filename:
                # í™•ì¥ì ì œê±°í•˜ê³  txtë¡œ ë³€ê²½
                filename = os.path.splitext(base_filename)[0] + ".txt"
            else:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"transcript_{timestamp}.txt"
            output_file = os.path.join(text_dir, filename)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            # ì„¸ê·¸ë¨¼íŠ¸ë³„ ìƒì„¸ ì •ë³´
            f.write("ì„¸ê·¸ë¨¼íŠ¸ë³„ ìƒì„¸:\n")
            f.write("-" * 30 + "\n")
            
            for segment in result["segments"]:
                start_time = self.format_time(segment["start"])
                end_time = self.format_time(segment["end"])
                f.write(f"[{start_time} - {end_time}] {segment['text']}\n")
        
        print(f"ë³€í™˜ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")
        return output_file
    
    def save_audio_file(self, uploaded_file):
        """
        ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ src/audioì— ì €ì¥ (ê°™ì€ ì´ë¦„ìœ¼ë¡œ)
        """
        # src/audio ë””ë ‰í† ë¦¬ ìƒì„±
        audio_dir = "src/audio"
        os.makedirs(audio_dir, exist_ok=True)
        
        # ì—…ë¡œë“œëœ íŒŒì¼ëª… ê·¸ëŒ€ë¡œ ì‚¬ìš©
        # base_filename = uploaded_file.name
        base_filename = datetime.now().strftime('%Y%m%d_%H%M%S')+'.'+os.path.splitext(uploaded_file.name)[1][1:]
        audio_path = os.path.join(audio_dir, base_filename)
        print(base_filename)
        # íŒŒì¼ ì €ì¥
        with open(audio_path, 'wb') as f:
            f.write(uploaded_file.getvalue())
        
        print(f"ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {audio_path}")
        return audio_path, base_filename
    
    def format_time(self, seconds):
        """
        ì´ˆë¥¼ MM:SS í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        """
        minutes = int(seconds // 60)
        seconds = int(seconds % 60)
        return f"{minutes:02d}:{seconds:02d}"
    
    def process_call_recording(self, audio_file, output_file=None, language="ko", base_filename=None):
        """
        í†µí™” ë…¹ìŒ íŒŒì¼ ì „ì²´ ì²˜ë¦¬ ê³¼ì •
        """
        try:
            # ìŒì„± ì¸ì‹ ìˆ˜í–‰
            result = self.transcribe_audio(audio_file, language)
            
            # ê²°ê³¼ ì¶œë ¥
            print("\n=== ë³€í™˜ ê²°ê³¼ ===")
            print(result["text"])
            
            # íŒŒì¼ë¡œ ì €ì¥ (ê°™ì€ ì´ë¦„ìœ¼ë¡œ)
            saved_file = self.save_transcript(result, output_file, base_filename)
            
            return {
                "success": True,
                "text": result["text"],
                "segments": result["segments"],
                "output_file": saved_file,
                "base_filename": base_filename
            }
            
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }

def main():
    parser = argparse.ArgumentParser(description="Whisperë¥¼ ì‚¬ìš©í•œ í†µí™” ë…¹ìŒ ìŒì„±ì¸ì‹")
    parser.add_argument("audio_file", help="ë³€í™˜í•  ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("-o", "--output", help="ì¶œë ¥ í…ìŠ¤íŠ¸ íŒŒì¼ëª…")
    parser.add_argument("-m", "--model", default="base", 
                       choices=["tiny", "base", "small", "medium", "large"],
                       help="Whisper ëª¨ë¸ í¬ê¸° (ê¸°ë³¸ê°’: base)")
    parser.add_argument("-l", "--language", default="ko", 
                       help="ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: ko)")
    
    args = parser.parse_args()
    
    # ìŒì„±ì¸ì‹ ë³€í™˜ê¸° ì´ˆê¸°í™”
    converter = VoiceToTextConverter(model_size=args.model)
    
    # í†µí™” ë…¹ìŒ íŒŒì¼ ì²˜ë¦¬
    result = converter.process_call_recording(
        audio_file=args.audio_file,
        output_file=args.output,
        language=args.language
    )
    
    if result["success"]:
        print(f"\nâœ… ë³€í™˜ ì™„ë£Œ!")
        print(f"ğŸ“„ ê²°ê³¼ íŒŒì¼: {result['output_file']}")
    else:
        print(f"\nâŒ ë³€í™˜ ì‹¤íŒ¨: {result['error']}")

if __name__ == "__main__":
    # ëª…ë ¹í–‰ ì¸ìˆ˜ê°€ ì—†ìœ¼ë©´ ì˜ˆì œ ì‹¤í–‰
    import sys
    if len(sys.argv) == 1:
        print("ì‚¬ìš©ë²•:")
        print("python practive_voice.py <ì˜¤ë””ì˜¤íŒŒì¼ê²½ë¡œ>")
        print("\nì˜ˆì‹œ:")
        print("python practive_voice.py call_recording.wav")
        print("python practive_voice.py call_recording.mp3 -o result.txt -m small")
        
        # í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ (ì‹¤ì œ íŒŒì¼ì´ ìˆì„ ë•Œë§Œ ì‹¤í–‰)
        test_file = "test_audio.wav"
        if os.path.exists(test_file):
            converter = VoiceToTextConverter()
            converter.process_call_recording(test_file)
    else:
        main()
